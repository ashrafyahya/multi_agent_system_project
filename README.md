# Competitor Analysis Multi-Agent System

A robust, scalable multi-agent system using LangGraph for automated competitor analysis with validation gates, retry mechanisms, and quality assurance.

## Overview

This system leverages multiple AI agents working together to perform comprehensive competitor analysis:

1. **Planner Agent**: Breaks down user requests into actionable tasks
2. **Supervisor Agent**: Controls workflow flow and applies business rules
3. **Data Collector Agent**: Gathers competitor data using web search and scraping
4. **Insight Agent**: Transforms raw data into business insights and SWOT analysis
5. **Report Agent**: Generates comprehensive formatted reports
6. **Export Agent**: Exports reports to PDF and generates visualizations (SWOT diagrams, charts)

The system uses LangGraph to orchestrate these agents through a stateful workflow with validation gates at each stage and automatic retry mechanisms for error recovery.

## Features

- ðŸ¤– **Multi-Agent Architecture**: Specialized agents for each workflow stage
- ðŸ”„ **Retry Logic**: Automatic retry with exponential backoff for transient failures
- âœ… **Validation Gates**: Quality checks at each workflow stage
- ðŸ“Š **Structured Output**: Pydantic models ensure type safety and validation
- ðŸ“„ **PDF Export**: Automatic PDF generation with proper markdown formatting
- ðŸ“ˆ **Visualizations**: SWOT diagrams, trends charts, and opportunities charts
- ðŸ›¡ï¸ **Error Handling**: Comprehensive error handling with custom exception hierarchy
- ðŸ“ **Comprehensive Testing**: Unit and integration tests with 80%+ coverage
- ðŸ”§ **Type Safety**: Full type hints throughout the codebase
- ðŸ“š **Well Documented**: Google-style docstrings with usage examples

## Architecture

![](diagrams/system_overview.png)

### Key Components

- **Agents**: Self-contained units following the Agent Pattern
- **Tools**: Stateless functions for web search, scraping, and text processing
- **Validators**: Quality gates ensuring output meets standards
- **Nodes**: Pure functions wrapping agent execution
- **Workflow**: LangGraph StateGraph with conditional edges

## Installation

### Prerequisites

- Python 3.10 or higher
- Groq API key (for LLM)
- Optional: Tavily API key (for enhanced web search)

### Setup

1. **Clone the repository**:
   ```bash
   git clone https://github.com/ashrafyahya/multi_agent_system_project.git
   cd multi_agent_system_project
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:
   Create a `.env` file in the project root:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   GROQ_MODEL=llama-3.1-8b-instant
   MAX_RETRIES=3
   LOG_LEVEL=INFO
   DATA_DIR=./data
   TAVILY_API_KEY=your_tavily_api_key_here 
   ```

## Configuration

Configuration is managed through environment variables. Create a `.env` file with the required variables.

### Required Configuration

- `GROQ_API_KEY`: Your Groq API key (required)
- `GROQ_MODEL`: Groq model to use (default: `llama-3.1-8b-instant`)

### Optional Configuration

- `MAX_RETRIES`: Maximum retry attempts (default: 3, range: 1-10)
- `LOG_LEVEL`: Logging level (default: `INFO`, options: DEBUG, INFO, WARNING, ERROR, CRITICAL)
- `DATA_DIR`: Directory for temporary data (default: `./data`)
- `TAVILY_API_KEY`: Tavily API key for enhanced web search (optional)

## Usage

### Command-Line Interface

```bash
python -m src.main "Analyze competitors in the SaaS market"
```

With verbose logging:
```bash
python -m src.main --verbose "Compare pricing strategies of top 5 competitors"
```

## Project Structure

```
multi_agent_system/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Main entry point
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                 # Agent implementations
â”‚   â”‚   â”œâ”€â”€ base_agent.py       # Base agent class
â”‚   â”‚   â”œâ”€â”€ planner_agent.py    # Plan generation
â”‚   â”‚   â”œâ”€â”€ supervisor_agent.py # Workflow control
â”‚   â”‚   â”œâ”€â”€ data_collector.py   # Data collection
â”‚   â”‚   â”œâ”€â”€ insight_agent.py    # Insight generation
â”‚   â”‚   â”œâ”€â”€ report_agent.py     # Report generation
â”‚   â”‚   â””â”€â”€ export_agent.py      # PDF export and visualizations
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                  # Workflow components
â”‚   â”‚   â”œâ”€â”€ workflow.py         # LangGraph workflow builder
â”‚   â”‚   â”œâ”€â”€ state.py            # WorkflowState TypedDict
â”‚   â”‚   â”œâ”€â”€ nodes/              # Pure function nodes
â”‚   â”‚   â”‚   â”œâ”€â”€ planner_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ supervisor_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ data_collector_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ insight_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ report_node.py
â”‚   â”‚   â”‚   â”œâ”€â”€ export_node.py
â”‚   â”‚   â”‚   â””â”€â”€ retry_node.py
â”‚   â”‚   â””â”€â”€ validators/         # Validation gates
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                   # Stateless tools
â”‚   â”‚   â”œâ”€â”€ web_search.py       # Web search tool
â”‚   â”‚   â”œâ”€â”€ scraper.py          # Web scraping tool
â”‚   â”‚   â”œâ”€â”€ query_generator.py   # Query optimization
â”‚   â”‚   â””â”€â”€ text_utils.py       # Text processing utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ plan_model.py       # Execution plan model
â”‚   â”‚   â”œâ”€â”€ competitor_profile.py # Competitor data model
â”‚   â”‚   â”œâ”€â”€ insight_model.py    # Business insights model
â”‚   â”‚   â””â”€â”€ report_model.py     # Report model
â”‚   â”‚
â”‚   â””â”€â”€ exceptions/              # Custom exception hierarchy
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”‚   â”œâ”€â”€ test_agents.py          # Agent tests
â”‚   â”œâ”€â”€ test_validators.py      # Validator tests
â”‚   â”œâ”€â”€ test_tools.py           # Tool tests
â”‚   â”œâ”€â”€ test_nodes.py           # Node tests
â”‚   â”œâ”€â”€ test_workflow.py        # Workflow tests
â”‚   â”œâ”€â”€ test_main.py            # Main entry point tests
â”‚   â””â”€â”€ integration/            # Integration tests
â”‚
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ pyproject.toml              # Project configuration
â”œâ”€â”€ Makefile                    # Development commands
â””â”€â”€ README.md                   # This file
```

## Development

### Running Tests

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ -v --cov=src --cov-report=html

# Run specific test file
pytest tests/test_agents.py -v
```

### Code Quality Checks

```bash
make lint          # Run ruff and bandit
make format        # Format with black and ruff
make type-check    # Run mypy type checking
make test-cov      # Run tests with coverage
```

### Pre-commit Hooks

Install pre-commit hooks to automatically run quality checks:
```bash
make pre-commit-install
```

## Architecture Overview

### Agent Pattern

All agents follow the Agent Pattern:
- **Self-contained**: Clear inputs/outputs
- **Stateless**: State passed in, not stored
- **Dependency Injection**: LLM and config injected via constructor
- **Communication**: Through state objects, not direct method calls

### Node Pattern

All nodes are pure functions:
- **Pure Functions**: `State -> State` with no side effects
- **Wrappers**: Wrap agent execution
- **Error Handling**: Graceful error handling

### Validator Pattern

All validators follow the Validator Pattern:
- **Composable**: Return `ValidationResult` objects
- **Non-throwing**: Don't raise exceptions for business rule violations
- **Structured**: Return errors and warnings

### Tool Pattern

All tools are stateless functions:
- **Stateless**: No internal state
- **Decorated**: Use `@tool` decorator from LangChain
- **Structured Output**: Return dictionaries with success/error information

## Workflow Flow

1. **User Query** â†’ Initial state created
2. **Planner Agent** â†’ Generates execution plan
3. **Supervisor Agent** â†’ Validates plan and routes to collector
4. **Data Collector Agent** â†’ Performs web search and scraping
5. **Collector Validator** â†’ Validates collected data quality
6. **Insight Agent** â†’ Generates SWOT analysis and insights
7. **Insight Validator** â†’ Validates insight quality
8. **Report Agent** â†’ Generates formatted report
9. **Report Validator** â†’ Validates report completeness
10. **Export Agent** â†’ Generates PDF and visualizations
11. **Final Report + Exports** â†’ Returned to user

If validation fails at any stage:
- Retry node modifies queries and retries (if retries available)
- Supervisor agent re-evaluates and routes accordingly
- Workflow ends if max retries exceeded

### Supervisor Agent Flow

The Supervisor Agent acts as the quality control and workflow coordinator:

![](diagrams/supervisor_agent_flow.png)

**Supervisor Responsibilities:**
- âœ… Validates outputs from Collector, Insight, and Report agents
- âœ… Controls workflow flow and routing decisions
- âœ… Enforces business rules (minimum sources, data quality, etc.)
- âœ… Triggers retry logic when validation fails
- âœ… Manages retry count and decides when to end workflow

## Testing

The project includes comprehensive test coverage:

- **Unit Tests**: Test individual components in isolation
- **Integration Tests**: Test complete workflow execution
- **Coverage**: 80%+ code coverage requirement

Run tests:
```bash
pytest tests/ -v --cov=src --cov-report=term-missing
```

## Troubleshooting

### Common Issues

**Issue**: `GROQ_API_KEY not found`
- **Solution**: Ensure `.env` file exists with `GROQ_API_KEY` set

**Issue**: `ModuleNotFoundError`
- **Solution**: Install dependencies: `pip install -r requirements.txt`

**Issue**: Workflow fails with validation errors
- **Solution**: Check `validation_errors` in result. May need to adjust query or increase `MAX_RETRIES`

**Issue**: Web search returns no results
- **Solution**: Ensure Tavily API key is set (optional but recommended) or check network connectivity

**Issue**: LLM rate limit errors
- **Solution**: Reduce concurrent requests or upgrade Groq API plan

### Debug Mode

Enable verbose logging:
```bash
python -m src.main --verbose "Your query"
```

Or set `LOG_LEVEL=DEBUG` in `.env` file.

## Contributing

1. Ensure all tests pass: `pytest tests/ -v`
2. Run code quality checks: `make lint`
3. Maintain 80%+ test coverage
4. Follow Google-style docstrings
5. Use type hints for all functions

## License

MIT License

## Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph)
- Uses [LangChain](https://github.com/langchain-ai/langchain) for LLM integration
- Powered by [Groq](https://groq.com/) for fast LLM inference

## Support

For issues, questions, or contributions, please open an issue on the repository.
